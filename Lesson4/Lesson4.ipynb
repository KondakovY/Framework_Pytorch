{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMPIn2Z0LYe3"
   },
   "source": [
    "## Домашнее задание:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1kh-e0oXz7V"
   },
   "source": [
    "1. Обучите CNN (самописная) на CIFAR-100.\n",
    "2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "OixdPSeBMIWt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from torchsummary import summary\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyIm9NKAVUZz"
   },
   "source": [
    "**1. Обучите CNN (самописная) на CIFAR-100.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "fqXZkK-tuSdH"
   },
   "outputs": [],
   "source": [
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]\n",
    "\n",
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.25, random_state=13)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oUPmuoFuEbP",
    "outputId": "c934c890-6b9a-46d2-9d4f-368eab2dae2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(root='data/', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "OnIVLrzYuEjQ"
   },
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "oNy0nngjz-R6"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "nVq53gyIuElq"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UhMQiuFzts6",
    "outputId": "e59be72b-62fa-4030-f715-7331c637dbb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches: 293\n",
      "Number of test batches: 98\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train batches: {len(train_loader)}')\n",
    "print(f'Number of test batches: {len(valid_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzR3xip8wtY7",
    "outputId": "59a3066a-5ebd-4827-efdb-afae10f75cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle']\n",
      "Number of classes: 100\n"
     ]
    }
   ],
   "source": [
    "classes = pickle.load(open('./data/cifar-100-python/meta', 'rb'))\n",
    "classes = classes['fine_label_names']\n",
    "\n",
    "print(classes[:10])\n",
    "print(f'Number of classes: {len(classes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "nYkC-0f8wtbd",
    "outputId": "e1f537a8-7f38-4b95-d0b6-e67472d73ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "fox\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img, lbl in train_loader:\n",
    "    print(img.shape)\n",
    "    print(classes[lbl[0]])\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "iPpe3oSbwteG",
    "outputId": "2c0c13df-83aa-4319-ef20-c5b1252c9799"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUyrKNoduEsO",
    "outputId": "ae76a116-24e8-4095-d8fb-f5c8cd33e213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv1): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=960, out_features=200, bias=True)\n",
      "  (dp1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=200, out_features=60, bias=True)\n",
      "  (dp2): Dropout(p=0.2, inplace=False)\n",
      "  (out): Linear(in_features=60, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()     \n",
    "                \n",
    "        self.bn1 = torch.nn.BatchNorm2d(3) \n",
    "        self.conv1 = torch.nn.Conv2d(3, 30, 3)\n",
    "\n",
    "        self.bn2 = torch.nn.BatchNorm2d(30) \n",
    "        self.conv2 = torch.nn.Conv2d(30, 60, 3)\n",
    "\n",
    "        self.bn3 = torch.nn.BatchNorm2d(60)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(960, 200)\n",
    "        self.dp1 = nn.Dropout(0.2)\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(200, 60)\n",
    "        self.dp2 = nn.Dropout(0.2)\n",
    "\n",
    "        self.out = torch.nn.Linear(60, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 3)\n",
    "        \n",
    "        x = self.bn2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp1(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)        \n",
    "        x = self.dp2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDaMCtXVuEye",
    "outputId": "211b8b11-2b8a-4f4a-ccce-dd37fc1e7661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
      "            Conv2d-2           [-1, 30, 30, 30]             840\n",
      "       BatchNorm2d-3           [-1, 30, 10, 10]              60\n",
      "            Conv2d-4             [-1, 60, 8, 8]          16,260\n",
      "       BatchNorm2d-5             [-1, 60, 4, 4]             120\n",
      "           Dropout-6                  [-1, 960]               0\n",
      "            Linear-7                  [-1, 200]         192,200\n",
      "           Dropout-8                  [-1, 200]               0\n",
      "            Linear-9                   [-1, 60]          12,060\n",
      "           Linear-10                  [-1, 100]           6,100\n",
      "================================================================\n",
      "Total params: 227,646\n",
      "Trainable params: 227,646\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.30\n",
      "Params size (MB): 0.87\n",
      "Estimated Total Size (MB): 1.18\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "cmrAlGha1w9S"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G942K8a31xAg",
    "outputId": "a58e51ef-ba5b-4d2d-9933-b0ab4c616d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/293]. Loss: 0.036. Acc: 0.023. Test acc: 0.011\n",
      "Epoch [2/10]. Step [1/293]. Loss: 0.030. Acc: 0.086. Test acc: 0.131\n",
      "Epoch [3/10]. Step [1/293]. Loss: 0.027. Acc: 0.148. Test acc: 0.187\n",
      "Epoch [4/10]. Step [1/293]. Loss: 0.025. Acc: 0.203. Test acc: 0.227\n",
      "Epoch [5/10]. Step [1/293]. Loss: 0.021. Acc: 0.328. Test acc: 0.245\n",
      "Epoch [6/10]. Step [1/293]. Loss: 0.023. Acc: 0.266. Test acc: 0.281\n",
      "Epoch [7/10]. Step [1/293]. Loss: 0.020. Acc: 0.305. Test acc: 0.291\n",
      "Epoch [8/10]. Step [1/293]. Loss: 0.021. Acc: 0.281. Test acc: 0.306\n",
      "Epoch [9/10]. Step [1/293]. Loss: 0.020. Acc: 0.352. Test acc: 0.305\n",
      "Epoch [10/10]. Step [1/293]. Loss: 0.021. Acc: 0.305. Test acc: 0.321\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        if i % 300 == 0:   \n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = net(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "       \n",
    "        net.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U2FPuQF8-ax"
   },
   "source": [
    "**2. Обучите CNN на CIFAR-100 через дообучение ImageNet Resnet-50.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYrDOCSE1xDP",
    "outputId": "de369c0a-c80b-4aa2-bed8-a1fb3889ce3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "uOeRYlWm_nKM"
   },
   "outputs": [],
   "source": [
    "for param in list(resnet50.parameters())[:]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "accSOYZu_nNO",
    "outputId": "1f8f13a7-79c0-41d8-8bf8-5d39a89dfe44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                  [-1, 100]         204,900\n",
      "================================================================\n",
      "Total params: 23,712,932\n",
      "Trainable params: 204,900\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 90.46\n",
      "Estimated Total Size (MB): 96.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet50.fc = nn.Linear(2048, 100)\n",
    "summary(resnet50.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "uxe1JfAl_nQD"
   },
   "outputs": [],
   "source": [
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "upwPU-9m_nSz"
   },
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in resnet50.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxEe19aA1xGY",
    "outputId": "ff611983-064d-4230-9348-a0707b67ab9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]. Step [1/293]. Loss: 0.037. Acc: 0.023. Test acc: 0.010\n",
      "Epoch [2/10]. Step [1/293]. Loss: 0.023. Acc: 0.328. Test acc: 0.246\n",
      "Epoch [3/10]. Step [1/293]. Loss: 0.021. Acc: 0.305. Test acc: 0.272\n",
      "Epoch [4/10]. Step [1/293]. Loss: 0.021. Acc: 0.336. Test acc: 0.271\n",
      "Epoch [5/10]. Step [1/293]. Loss: 0.021. Acc: 0.320. Test acc: 0.288\n",
      "Epoch [6/10]. Step [1/293]. Loss: 0.017. Acc: 0.414. Test acc: 0.286\n",
      "Epoch [7/10]. Step [1/293]. Loss: 0.017. Acc: 0.453. Test acc: 0.287\n",
      "Epoch [8/10]. Step [1/293]. Loss: 0.018. Acc: 0.406. Test acc: 0.291\n",
      "Epoch [9/10]. Step [1/293]. Loss: 0.018. Acc: 0.398. Test acc: 0.294\n",
      "Epoch [10/10]. Step [1/293]. Loss: 0.016. Acc: 0.539. Test acc: 0.296\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "resnet50.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        if i % 300 == 0: \n",
    "            resnet50.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = resnet50(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "        resnet50.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_CNN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
